shaohua@shaohua:/media/shaohua/Outerspace/corpus$ ./bench.sh 
PSD:
Read sim testset ./testsets/ws/ws353_similarity.txt
Read sim testset ./testsets/ws/ws353_relatedness.txt
Read sim testset ./testsets/ws/bruni_men.txt
Read sim testset ./testsets/ws/radinsky_mturk.txt
Read sim testset ./testsets/ws/luong_rare.txt
Read sim testset ./testsets/ws/simlex_999a.txt
Read analogy testset ./testsets/analogy/google.txt
Read analogy testset ./testsets/analogy/msr.txt

Loading bigram file 'top2grams-wiki.txt':
Totally 277025 words
277025 words seen, top 25000 & 0 extra to keep. 25000 kept
Read bigrams:
25000
Cut point 4010: 4/0.000%
Cut point 2005: 23/0.000%
Cut point 1002: 123/0.000%
Cut point 501: 840/0.000%
Cut point 251: 5383/0.001%
Cut point 125: 28276/0.005%
Cut point 63: 124146/0.020%
Cut point 31: 493469/0.079%
Cut point 16: 1779998/0.285%
493469 (0.079%) elements in Weight-1 cut off at 31.33

4 iterations of EM
Begin EM of weighted factorization by bigram freqs

EM Iter 1:
Begin unweighted factorization
12450 positive eigenvalues, sum: 1016404.875
Eigenvalues cut at the 503-th, 186.957 ~ 186.925
All eigen sum: 1961478.500, Kept eigen sum: 178549.484
nowe_factorize() elapsed: 1936.64
L1 Weighted: Gi: 7769817.151, VV: 7350854.952, Gsym-VV: 10842411.309, G-VV: 9977720.915
Precompute cosine matrix, will need 2.5GB RAM... Done.
ws353_similarity: 203 test pairs, 195 valid , 0.79632
ws353_relatedness: 252 test pairs, 241 valid , 0.68286
bruni_men: 3000 test pairs, 2639 valid , 0.77234
radinsky_mturk: 287 test pairs, 279 valid , 0.68298
luong_rare: 2034 test pairs, 396 valid , 0.54562
simlex_999a: 999 test pairs, 945 valid , 0.39870
19500/12552/19544: Add 0.66651, Mul 0.68634
google: 19544 analogies, 12586 valid . Add Score: 0.66590, Mul Score: 0.68584
8000/5030/8000: Add 0.54732, Mul 0.59761
msr: 8000 analogies, 5030 valid . Add Score: 0.54732, Mul Score: 0.59761
EM iter 1 elapsed: 1954.66

EM Iter 2:
Begin unweighted factorization
12338 positive eigenvalues, sum: 239171.609
Eigenvalues cut at the 502-th, 191.346 ~ 190.984
All eigen sum: 299793.500, Kept eigen sum: 180740.391
nowe_factorize() elapsed: 1972.69
L1 Weighted: Gi: 7878353.598, VV: 7242558.205, Gsym-VV: 10491300.183, G-VV: 9662005.122
Precompute cosine matrix, will need 2.5GB RAM... Done.
ws353_similarity: 203 test pairs, 195 valid , 0.79887
ws353_relatedness: 252 test pairs, 241 valid , 0.68380
bruni_men: 3000 test pairs, 2639 valid , 0.77014
radinsky_mturk: 287 test pairs, 279 valid , 0.68362
luong_rare: 2034 test pairs, 396 valid , 0.54914
simlex_999a: 999 test pairs, 945 valid , 0.39755
19500/12552/19544: Add 0.67049, Mul 0.69025
google: 19544 analogies, 12586 valid . Add Score: 0.66995, Mul Score: 0.68981
8000/5030/8000: Add 0.54274, Mul 0.59543
msr: 8000 analogies, 5030 valid . Add Score: 0.54274, Mul Score: 0.59543
EM iter 2 elapsed: 1990.84

EM Iter 3:
Begin unweighted factorization
12334 positive eigenvalues, sum: 240251.656
Eigenvalues cut at the 501-th, 195.408 ~ 194.607
All eigen sum: 299763.188, Kept eigen sum: 183383.266
nowe_factorize() elapsed: 1932.79
L1 Weighted: Gi: 7861670.004, VV: 7228707.970, Gsym-VV: 10272011.447, G-VV: 9453111.101
Precompute cosine matrix, will need 2.5GB RAM... Done.
ws353_similarity: 203 test pairs, 195 valid , 0.80074
ws353_relatedness: 252 test pairs, 241 valid , 0.68146
bruni_men: 3000 test pairs, 2639 valid , 0.76744
radinsky_mturk: 287 test pairs, 279 valid , 0.68036
luong_rare: 2034 test pairs, 396 valid , 0.55140
simlex_999a: 999 test pairs, 945 valid , 0.39524
19500/12552/19544: Add 0.67081, Mul 0.69383
google: 19544 analogies, 12586 valid . Add Score: 0.67027, Mul Score: 0.69355
8000/5030/8000: Add 0.53917, Mul 0.58847
msr: 8000 analogies, 5030 valid . Add Score: 0.53917, Mul Score: 0.58847
EM iter 3 elapsed: 1950.92

EM Iter 4:
Begin unweighted factorization
12339 positive eigenvalues, sum: 241826.562
Eigenvalues cut at the 500-th, 199.922 ~ 198.961
All eigen sum: 300269.469, Kept eigen sum: 186190.469
nowe_factorize() elapsed: 2069.77
L1 Weighted: Gi: 7879650.000, VV: 7250952.037, Gsym-VV: 10122656.270, G-VV: 9301310.810
Precompute cosine matrix, will need 2.5GB RAM... Done.
ws353_similarity: 203 test pairs, 195 valid , 0.80089
ws353_relatedness: 252 test pairs, 241 valid , 0.67612
bruni_men: 3000 test pairs, 2639 valid , 0.76526
radinsky_mturk: 287 test pairs, 279 valid , 0.67757
luong_rare: 2034 test pairs, 396 valid , 0.55358
simlex_999a: 999 test pairs, 945 valid , 0.39342
19500/12552/19544: Add 0.67145, Mul 0.69487
google: 19544 analogies, 12586 valid . Add Score: 0.67098, Mul Score: 0.69466
8000/5030/8000: Add 0.53320, Mul 0.58569
msr: 8000 analogies, 5030 valid . Add Score: 0.53320, Mul Score: 0.58569
EM iter 4 elapsed: 2087.96
we_factorize_EM() elapsed: 7987.32

Save matrix 'V' into 25000-500-EM.vec


real	137m4.155s
user	815m28.416s
sys	97m3.316s
Using Tikhonov regularization with coeff: 2.0
Read sim testset ./testsets/ws/ws353_similarity.txt
Read sim testset ./testsets/ws/ws353_relatedness.txt
Read sim testset ./testsets/ws/bruni_men.txt
Read sim testset ./testsets/ws/radinsky_mturk.txt
Read sim testset ./testsets/ws/luong_rare.txt
Read sim testset ./testsets/ws/simlex_999a.txt
Read analogy testset ./testsets/analogy/google.txt
Read analogy testset ./testsets/analogy/msr.txt

Embeddings of all words in '25000-500-EM.vec' will be loaded as core
Load embedding text file '25000-500-EM.vec'
Will load embeddings of 25000 words
25000    25000    0    
25000 embeddings read, 25000 kept
2 blocks of 25000 core words and 55000 noncore words will be loaded. Skip 0 words
Loading bigram file 'top2grams-wiki.txt' into 2 blocks. Will skip 0 words
Totally 277025 words
277025 words in file, top 80000 to read into vocab (25000 core, 55000 noncore), 0 skipped
Read bigrams:
25000 (25000 core, 0 noncore)
25000 core words are all read.
80000 (25000 core, 55000 noncore)
Cut point 35: 2419/0.000%
Cut point 18: 48813/0.004%
2414 (0.000%) elements in Weight-1 cut off at 35.48
1328 (0.000%) elements in Weight-2 cut off at 35.48

del G1, G21
Begin finding embeddings of non-core words
55000 / 55000. Elapsed: 5851.77/10.41 
del F21, WGsum, VW
Save matrix 'V' into 25000-80000-500-BLK-2.0.vec
Test embeddings derived from block factorization

Precompute cosine matrix, will need 25.6GB RAM... Done.
ws353_similarity: 203 test pairs, 203 valid , 0.79212
ws353_relatedness: 252 test pairs, 252 valid , 0.67948
bruni_men: 3000 test pairs, 3000 valid , 0.76389
radinsky_mturk: 287 test pairs, 285 valid , 0.67397
luong_rare: 2034 test pairs, 835 valid , 0.48215
simlex_999a: 999 test pairs, 995 valid , 0.39890
19500/18401/19544: Add 0.61893, Mul 0.63926
google: 19544 analogies, 18443 valid . Add Score: 0.61866, Mul Score: 0.63921
8000/6172/8000: Add 0.49579, Mul 0.54277
msr: 8000 analogies, 6172 valid . Add Score: 0.49579, Mul Score: 0.54277

real	109m26.625s
user	896m3.444s
sys	278m1.332s
Using Tikhonov regularization with coeff: 4.0
Read sim testset ./testsets/ws/ws353_similarity.txt
Read sim testset ./testsets/ws/ws353_relatedness.txt
Read sim testset ./testsets/ws/bruni_men.txt
Read sim testset ./testsets/ws/radinsky_mturk.txt
Read sim testset ./testsets/ws/luong_rare.txt
Read sim testset ./testsets/ws/simlex_999a.txt
Read analogy testset ./testsets/analogy/google.txt
Read analogy testset ./testsets/analogy/msr.txt

Embeddings of top 25000 words in '25000-80000-500-BLK-2.0.vec' will be loaded as core
Load embedding text file '25000-80000-500-BLK-2.0.vec'
Will load embeddings of 80000 words
80000    80000    0    
80000 embeddings read, 80000 kept
2 blocks of 25000 core words and 50000 noncore words will be loaded. Skip 55000 words
Loading bigram file 'top2grams-wiki.txt' into 2 blocks. Will skip 55000 words
Totally 277025 words
277025 words in file, top 75000 to read into vocab (25000 core, 50000 noncore), 55000 skipped
Read bigrams:
25000 (25000 core, 0 noncore)
25000 core words are all read.
130000 (25000 core, 50000 noncore)
124073 (0.010%) elements in Weight-1 cut off at 6.63
111102 (0.009%) elements in Weight-2 cut off at 6.63

del G1, G21
Begin finding embeddings of non-core words
50000 / 50000. Elapsed: 5291.71/10.41 
del F21, WGsum, VW
Save matrix 'V' into 25000-130000-500-BLK-4.0.vec
Test embeddings derived from block factorization

ws353_similarity: 203 test pairs, 203 valid , 0.79212
ws353_relatedness: 252 test pairs, 252 valid , 0.67948
bruni_men: 3000 test pairs, 3000 valid , 0.76389
radinsky_mturk: 287 test pairs, 286 valid , 0.67566
luong_rare: 2034 test pairs, 1096 valid , 0.47344
simlex_999a: 999 test pairs, 996 valid , 0.39715
19500/19158/19544: Add 0.60680, Mul 0.62778
google: 19544 analogies, 19202 valid . Add Score: 0.60650, Mul Score: 0.62770
8000/6578/8000: Add 0.48100, Mul 0.52676
msr: 8000 analogies, 6578 valid . Add Score: 0.48100, Mul Score: 0.52676

real	106m34.491s
user	911m26.380s
sys	262m26.192s
Using Tikhonov regularization with coeff: 8.0
Read sim testset ./testsets/ws/ws353_similarity.txt
Read sim testset ./testsets/ws/ws353_relatedness.txt
Read sim testset ./testsets/ws/bruni_men.txt
Read sim testset ./testsets/ws/radinsky_mturk.txt
Read sim testset ./testsets/ws/luong_rare.txt
Read sim testset ./testsets/ws/simlex_999a.txt
Read analogy testset ./testsets/analogy/google.txt
Read analogy testset ./testsets/analogy/msr.txt

Embeddings of top 25000 words in '25000-130000-500-BLK-4.0.vec' will be loaded as core
Load embedding text file '25000-130000-500-BLK-4.0.vec'
Will load embeddings of 130000 words
130000    130000    0    
130000 embeddings read, 130000 kept
2 blocks of 25000 core words and 50000 noncore words will be loaded. Skip 105000 words
Loading bigram file 'top2grams-wiki.txt' into 2 blocks. Will skip 105000 words
Totally 277025 words
277025 words in file, top 75000 to read into vocab (25000 core, 50000 noncore), 105000 skipped
Read bigrams:
25000 (25000 core, 0 noncore)
25000 core words are all read.
180000 (25000 core, 50000 noncore)
191415 (0.015%) elements in Weight-1 cut off at 4.12
183822 (0.015%) elements in Weight-2 cut off at 4.12

del G1, G21
Begin finding embeddings of non-core words
50000 / 50000. Elapsed: 5277.66/10.72 
del F21, WGsum, VW
Save matrix 'V' into 25000-180000-500-BLK-8.0.vec
Test embeddings derived from block factorization

ws353_similarity: 203 test pairs, 203 valid , 0.79212
ws353_relatedness: 252 test pairs, 252 valid , 0.67948
bruni_men: 3000 test pairs, 3000 valid , 0.76389
radinsky_mturk: 287 test pairs, 286 valid , 0.67566
luong_rare: 2034 test pairs, 1260 valid , 0.45688
simlex_999a: 999 test pairs, 998 valid , 0.39788
19500/19320/19544: Add 0.60041, Mul 0.62158
google: 19544 analogies, 19364 valid . Add Score: 0.60013, Mul Score: 0.62151
8000/7054/8000: Add 0.46187, Mul 0.50383
msr: 8000 analogies, 7054 valid . Add Score: 0.46187, Mul Score: 0.50383

real	111m53.430s
user	964m38.856s
sys	271m9.988s
word2vec:
Starting training using file /home/shaohua/D/corpus/cleanwiki.txt
Vocab size: 289625
Words in train file: 2000719401
Alpha: 0.000053  Progress: 99.89%  Words/thread/sec: 65.89k  
real	249m8.382s
user	2530m25.988s
sys	4m4.680s
glove:
BUILDING VOCABULARY
Processed 2042546400 tokens.
Counted 8527820 unique words.
Truncating vocabulary at min count 100.
Using vocabulary of size 289624.

COUNTING COOCCURRENCES
window size: 3
context: symmetric
max product: 50983620
overflow length: 152113425
Reading vocab from file "vocab-wiki.txt"...loaded 289624 words.
Building lookup table...table contains 428261749 elements.
Processed 2042546400 tokens.
Writing cooccurrences to disk..........8 files in total.
Merging cooccurrence files: processed 652989173 lines.

SHUFFLING COOCCURRENCES
array size: 1020054732
Shuffling by chunks: processed 652989173 lines.
Wrote 1 temporary file(s).
Merging temp files: processed 652989173 lines.

TRAINING MODEL
Read 652989173 lines.
Initializing parameters...done.
vector size: 500
vocab size: 289624
x_max: 10.000000
alpha: 0.750000
iter: 001, cost: 0.131547
iter: 002, cost: 0.105234
iter: 003, cost: 0.090557
iter: 004, cost: 0.080886
iter: 005, cost: 0.075276
iter: 006, cost: 0.071524
iter: 007, cost: 0.068758
iter: 008, cost: 0.066837
iter: 009, cost: 0.065186
iter: 010, cost: 0.063919
iter: 011, cost: 0.062813
iter: 012, cost: 0.061871
iter: 013, cost: 0.061140
iter: 014, cost: 0.060471
iter: 015, cost: 0.059661

real	229m37.019s
user	1503m26.736s
sys	9m14.064s
singular:
Counting words in file 1/1 .......... 6058672 types
Sliding window in file 1/1 ..........
Writing counts
Loading counts
Calculating SVD
Clustering

real	183m26.164s
user	87m43.676s
sys	29m32.096s

PMI2:
15239.57user 3723.37system 4:37:35elapsed 113%CPU (0avgtext+0avgdata 9739144maxresident)k
99330104inputs+7182248outputs (88major+399600177minor)pagefaults 0swaps
59223.84user 82148.26system 36:36:14elapsed 107%CPU (0avgtext+0avgdata 31071304maxresident)k
485837760inputs+23424872outputs (109major+7607047364minor)pagefaults 0swaps
10169.24user 122.85system 2:53:15elapsed 99%CPU (0avgtext+0avgdata 24847900maxresident)k
11854888inputs+4056outputs (47major+6317122minor)pagefaults 0swaps
